# Техническое видение проекта OCR обработки бланков ОТК

## Описание проекта

Проект предназначен для автоматической обработки отсканированных бланков ОТК с помощью OCR технологий. Система выполняет полный цикл обработки: от предварительной подготовки изображений до создания структурированных JSON данных.

## Технологии и фреймворки

**Основные технологии:**
- **Python 3.9+** - основной язык разработки
- **OpenCV** - предобработка изображений (коррекция, улучшение качества)
- **PaddleOCR** - OCR движок для распознавания текста
- **Pydantic** - валидация данных и настроек
- **JSON** - формат вывода данных

**Дополнительные библиотеки:**
- **NumPy** - работа с массивами изображений
- **Pillow** - дополнительная обработка изображений
- **pathlib** - работа с файловой системой
- **logging** - встроенное логирование Python

**Инфраструктура:**
- **Виртуальное окружение Python (venv)** - изоляция зависимостей
- **requirements.txt** - управление зависимостями

## Повышение качества OCR

**Принцип: улучшение точности распознавания через постобработку**

### Словарь исправления ошибок

**Проблема:** PaddleOCR часто допускает типичные ошибки при распознавании русского текста, особенно в специфических терминах бланков ОТК.

**Решение:** Статический словарь частых ошибок для автоматической коррекции:

```python
# src/config/corrections.py
OCR_CORRECTIONS = {
    # Заголовки и метаданные
    "Homep": "Номер",
    "PeB": "Рев",
    "Wmyyep": "Изделие",
    
    # Статусы и решения
    "ne ugim": "не соответствует",
    "друие несоотвтствуя": "другие несоответствия",
    "годн": "годен",
    "бракк": "брак",
    
    # Технические термины
    "ГЕОМЕТРИЯ": "ГЕОМЕТРИЯ",  # Эталонное написание
    "ОТВЕРСТИЯ": "ОТВЕРСТИЯ",
    "РЕЗЬБА": "РЕЗЬБА"
}
```

**Применение:**
- Автоматическая коррекция после OCR
- Логирование исправлений для анализа
- Возможность расширения словаря

### Валидация полей формы

**Типы валидации:**

1. **Числовые поля** - проверка формата чисел, диапазонов
2. **Даты** - валидация формата DD.MM.YYYY
3. **Обязательные поля** - проверка наличия критичных данных
4. **Текстовые паттерны** - проверка соответствия ожидаемым шаблонам

**Правила валидации:**
```python
VALIDATION_RULES = {
    "act_number": {
        "pattern": r"\d+/\d+",
        "required": True,
        "example": "001/2025"
    },
    "date": {
        "pattern": r"\d{1,2}\.\d{1,2}\.\d{4}",
        "required": True,
        "example": "15.10.2025"
    },
    "quantities": {
        "pattern": r"\d+",
        "type": "integer",
        "min": 0
    }
}
```

### Управление порогом уверенности

**Стратегия:**
- **Базовый порог** (0.5) - минимальная уверенность для принятия текста
- **Предупреждение** (0.6) - логирование низкой уверенности
- **Высокая уверенность** (0.8+) - надежные данные

**Обработка низкой уверенности:**
- Логирование проблемных областей
- Пометка в итоговом JSON
- Возможность ручной проверки

### Подход к детекции зон

**RegionDetector** использует каскад стратегий:

1. **Adaptive** — поиск горизонтальных линий (морфология + `findContours`)
2. **Text-based** — анализ горизонтальной проекции текста для «безбордерных» таблиц
3. **Template** — нормализованные шаблоны с fallback на пропорциональное деление

Шаблоны хранятся в файле `config/templates/regions.json` (если файл отсутствует, используются встроенные значения из `src/config/region_templates.py`). Все координаты задаются в долях высоты документа, что позволяет работать с любым разрешением.

**Преимущества:**
- Высокая точность для стандартных бланков (шаблоны)
- Гибкость при вариациях формата (адаптивные и текстовые методы)
- Устойчивость к искажениям за счёт каскадной стратегии и fallback

### FormExtractor - Структурирование данных

**Модуль:** `src/form_extractor.py`

Извлекает структурированные бизнес-данные из региональных OCR результатов.

**Входные данные:** `*-corrected.json` с региональным распознаванием (`ocr_results_by_region`)

**Выходные данные:** `*-data.json` со структурой:
- `header`: реквизиты документа (номер акта, дата, контролёр, количества)
- `defects`: блоки таблиц дефектов (геометрия, отверстия, поверхность)
- `analysis`: анализ отклонений и финальное решение

**Ключевые возможности:**

1. **Детекция наклейки (приоритетный источник)**
   - Определение по ключевым словам и компактности группы
   - Извлечение полей: строка, количество, заказ, дата, клиент
   - Наклейка имеет приоритет над рукописными данными

2. **Извлечение header секции**
   - Номер акта (паттерн `XXX/YY`, верхний правый угол)
   - Дата акта (формат `DD.MM.YYYY`)
   - Тип бланка (ревизия, например `A3`)
   - Количественные показатели (проверено, с дефектами, годно)
   - Тип контроля (операционный/входной/выходной)
   - ФИО контролёра ОТК

3. **Парсинг defects зоны**
   - Разделение на 2-3 горизонтальных блока по X-координате (промежутки > 300px)
   - Классификация блоков: геометрия, отверстия, поверхность
   - Группировка текстов в строки таблиц по Y-координате (tolerance = 20px)
   - Определение колонок по позиции и заголовкам

4. **Парсинг analysis зоны**
   - Таблица отклонений (№ п/п, Операция, Причина, Виновный, Решение)
   - Финальное решение (использовать/доработать/не использовать)
   - Подписи руководителя и представителя ОТК

5. **Валидация данных**
   - Проверка обязательных полей header
   - Пометка сомнительных значений (низкая уверенность < 0.7)
   - Валидация форматов (дата, номер акта)

**Структура данных:**

Использует простые dataclasses (KISS принцип):
- `FieldValue`: поле с метаданными (value, confidence, source, suspicious)
- `HeaderData`: структура header секции
- `StickerData`: данные наклейки
- `DefectBlock`: блок таблицы дефектов
- `DefectRow`: строка таблицы дефектов
- `AnalysisData`: структура analysis секции
- `AnalysisRow`: строка таблицы отклонений
- `FinalDecision`: финальное решение

**Алгоритмы:**

1. **Горизонтальные блоки:** сортировка по X, поиск промежутков > 300px
2. **Группировка строк:** сортировка по Y, группировка по tolerance (20px)
3. **Детекция наклейки:** компактность группы (x_range < 400px, y_range < 300px)
4. **Извлечение полей:** поиск по ключевым словам и координатам

**Обработка ошибок:**

- Graceful degradation: продолжение работы при частичных сбоях
- Логирование проблемных полей
- Пометка сомнительных значений
- Валидация обязательных полей с отчетами об ошибках

**Интеграция:**

- Автоматически выполняется после валидации (Step 5 в пайплайне)
- Интегрирован в batch_processor для пакетной обработки
- Использует региональные OCR результаты из `process_regions()`

### Table Detection and Cell-by-Cell OCR (Optional Enhancement)

**Модуль:** `src/table_detector.py`, `src/table_processor.py`

Когда включено (`enable_table_detection=True`), зона defects проходит специализированную обработку таблиц:

1. **Table Structure Detection:**
   - Использует морфологические операции для детекции горизонтальных и вертикальных линий
   - Извлекает структуру таблицы с границами строк/столбцов
   - Валидирует структуру (минимум 2 строки/столбца, разумные промежутки)

2. **Cell-by-Cell OCR:**
   - Извлекает отдельные ячейки на основе обнаруженной сетки
   - Запускает OCR для каждой ячейки отдельно (улучшает точность на 10-25%)
   - Применяет предобработку на уровне ячеек (усиление контраста, шумоподавление)
   - Сохраняет структурированные данные с метаданными строк/столбцов

3. **Structured Output:**
   - Каждая ячейка содержит: позицию, текст, уверенность, тип поля
   - Строки предварительно сгруппированы по детекции сетки (не требуется кластеризация по Y-координатам)
   - Маппинг столбцов из шаблона или автоматическая детекция

4. **Fallback Strategy:**
   - Если детекция таблицы не удалась, автоматически переходит к стандартному плоскому OCR
   - Сохраняет обратную совместимость с существующим пайплайном
   - Graceful degradation гарантирует отсутствие потери данных

**Конфигурация:**
- `enable_table_detection` - Включить/выключить обработку таблиц
- `table_detection_strategy` - "morphology" (по умолчанию), "template", или "auto"
- `table_h_kernel_ratio` / `table_v_kernel_ratio` - Размеры ядер для детекции линий
- Шаблонная детекция доступна через `table_templates.json`

**Интеграция:**
- Автоматически активируется для зоны "defects" в `OCREngine.process_regions()`
- Результаты сохраняются в `table_data_by_region` в JSON выходе
- `FormExtractor` автоматически определяет формат данных (таблица или плоский OCR)

### Parallel OCR Processing

**Модуль:** `src/parallel_ocr_worker.py`, `src/ocr_engine_factory.py`

Система поддерживает параллельную обработку OCR для ускорения обработки больших документов и таблиц.

**Архитектура:**

1. **Parallel Table Cell Processing:**
   - Таблицы с большим количеством ячеек (≥10) обрабатываются параллельно
   - Каждая ячейка обрабатывается в отдельном worker процессе
   - Используется `ProcessPoolExecutor` для распределения нагрузки
   - Каждый worker инициализирует свой собственный recognition-only OCR engine

2. **Parallel Region Processing:**
   - Документы с несколькими регионами (≥2) обрабатываются параллельно
   - Каждый регион обрабатывается в отдельном worker процессе
   - Поддержка двух режимов:
     - **Simple parallel:** каждый worker использует full OCR engine
     - **Det+Rec split:** разделение на detection и recognition (рекомендуется, в разработке)

3. **OCR Engine Factory:**
   - Централизованное создание OCR engines разных типов
   - `create_full_engine()` - полный engine (detection + recognition + classification)
   - `create_detection_engine()` - только детекция текста
   - `create_recognition_engine()` - только распознавание текста

**Конфигурация:**

```bash
# Включить параллельную обработку
ENABLE_PARALLEL_PROCESSING=true

# Количество worker процессов
PARALLEL_REGIONS_WORKERS=4  # Для обработки регионов
PARALLEL_CELLS_WORKERS=6    # Для обработки ячеек таблиц

# Использовать разделение detection/recognition (рекомендуется)
PARALLEL_USE_SEPARATE_ENGINES=true

# Пороги для активации параллельного режима
PARALLEL_MIN_REGIONS_FOR_PARALLELIZATION=2
PARALLEL_MIN_CELLS_FOR_PARALLELIZATION=10
```

**Производительность:**

- **Table processing:** 2-4x ускорение для таблиц с 20+ ячейками
- **Region processing:** 2-3x ускорение для документов с 3+ регионами
- **Memory usage:** увеличение на 200-500MB (несколько OCR engines в workers)

**Оптимизация:**

- Параллелизация активируется только при превышении порогов (избегает overhead для маленьких документов)
- Автоматический fallback на sequential режим при ошибках
- Настраиваемое количество workers в зависимости от CPU cores
- Логирование метрик производительности (время, speedup factor)

**Примеры логов:**

```
Table processing: 45 cells in 3.2s (parallel, 6 workers) vs 8.7s (sequential) - 2.7x speedup
Region processing: 4 regions in 1.8s (parallel, 4 workers) vs 5.1s (sequential) - 2.8x speedup
```

**Обработка ошибок:**

- Graceful fallback на sequential режим при сбоях
- Логирование ошибок без прерывания обработки
- Сохранение частичных результатов

**Интеграция:**

- Автоматически используется в `TableProcessor.extract_cells()` для больших таблиц
- Автоматически используется в `OCREngine.process_regions()` для документов с несколькими регионами
- Можно отключить через `ENABLE_PARALLEL_PROCESSING=false`

## Принципы разработки

**KISS Philosophy:**
- **Максимальная простота решений** - выбираем простейшее работающее решение
- **Никакого оверинжиниринга** - не усложняем архитектуру заранее
- **YAGNI** - не добавляем то, что не нужно сейчас
- **Единственная ответственность** - один модуль = одна функция

**Итеративный подход:**
- **MVP-first** - сначала минимально работающая версия
- **Быстрые циклы** разработка → тест → обратная связь
- **Fail fast, learn fast** - быстрое выявление и исправление ошибок

**Качество кода:**
- **Читаемость важнее оптимизации** - понятный код важнее быстрого
- **Простые, понятные решения** - избегаем "умных" решений
- **Рефакторинг при необходимости, но не заранее**

**Архитектурные принципы:**
- **Модульность** - четкое разделение по функциональности
- **Stateless** - модули не хранят состояние между запусками
- **Единственная ответственность** - каждый модуль решает одну задачу

## Структура проекта

```
Image_ocr/
├── src/                          # Исходный код
│   ├── __init__.py
│   ├── main.py                   # Основной модуль-оркестратор
│   ├── preprocessor.py           # Предобработка изображений (OpenCV)
│   ├── region_detector.py        # Детекция и извлечение зон документа
│   ├── ocr_engine.py            # OCR распознавание (PaddleOCR)
│   ├── error_corrector.py       # Постобработка и коррекция ошибок
│   ├── field_validator.py       # Валидация полей формы
│   ├── form_extractor.py        # Извлечение структурированных данных
│   ├── batch_processor.py       # Пакетная обработка файлов
│   ├── config/
│   │   ├── __init__.py
│   │   ├── settings.py          # Настройки приложения
│   │   ├── corrections.py       # Словарь исправлений OCR
│   │   ├── validation_rules.py  # Правила валидации полей
│   │   └── region_templates.py  # Шаблоны регионов
│   ├── models/
│   │   ├── __init__.py
│   │   └── form_data.py         # Dataclass-модели данных (FieldValue, HeaderData, DefectBlock, etc.)
│   └── utils/
│       ├── __init__.py
│       └── memory_monitor.py    # Мониторинг памяти
├── images/                      # Входные изображения
├── results/                     # Результаты обработки
├── docs/                        # Документация
├── tests/                       # Тесты (при необходимости)
├── requirements.txt             # Зависимости
├── .env.example                # Пример конфигурации
└── README.md                   # Основная документация
```

**Принципы организации:**
- Плоская структура модулей (без глубокой вложенности)
- Один файл = одна основная функция
- Четкое разделение входных данных, кода и результатов

## Архитектура проекта

**Архитектурный паттерн: Pipeline (Конвейер)**

```
Изображение → Предобработка → Детекция зон → OCR → Коррекция ошибок → Валидация → Структурирование → JSON → Результат
```

**Компоненты пайплайна:**

1. **ImagePreprocessor** - коррекция искажений, улучшение качества
   - Перспективная коррекция (perspective correction) - исправление искажений при фотографировании документов под углом
   - Коррекция наклона (deskew) - выравнивание текста по горизонтали
   - Улучшение качества изображения (масштабирование, шумоподавление, контраст)
2. **RegionDetector** - комбинированная детекция и извлечение зон
   - Каскад стратегий: адаптивные линии → проекция текста → шаблоны
   - Нормализованные координаты (0.0–1.0) для независимости от разрешения
   - Загрузка шаблонов из файла `config/templates/regions.json` (при наличии)
3. **OCREngine** - распознавание текста в найденных зонах
   - Интеграция PaddleOCR
   - Фильтрация по порогу уверенности
4. **ErrorCorrector** - постобработка результатов OCR
   - Применение словаря исправлений
   - Логирование коррекций
5. **FieldValidator** - валидация извлеченных данных
   - Проверка форматов (даты, числа)
   - Валидация обязательных полей
   - Проверка паттернов
6. **FormExtractor** - извлечение структурированных данных формы
   - Извлечение данных header секции (номер акта, дата, инспектор)
   - Детекция наклейки (приоритетный источник данных)
   - Разделение defects зоны на горизонтальные блоки (геометрия/отверстия/поверхность)
   - Группировка текстов в строки таблиц по Y-координате
   - Парсинг таблиц дефектов и анализа отклонений
   - Валидация обязательных полей header
   - Пометка сомнительных значений (низкая уверенность)
7. **JSONBuilder** - создание итоговой структуры данных
   - Формирование валидного JSON
   - Добавление метаданных обработки

**Принципы взаимодействия:**
- Каждый компонент получает входные данные и возвращает результат
- Линейная последовательность обработки
- Каждый этап сохраняет промежуточные результаты в `/results/`
- Главный модуль `main.py` оркестрирует весь процесс

**Обработка ошибок:**
- Логирование на каждом этапе
- Graceful degradation - продолжение работы при частичных сбоях
- Сохранение промежуточных результатов для отладки

**Управление ресурсами:**
- Context manager паттерн для OCR движка
- Явное управление жизненным циклом через `__enter__`/`__exit__`
- Автоматическая очистка ресурсов после обработки

## Модель данных

**Промежуточные данные (между этапами):**

1. **Предобработанное изображение** → файл с постфиксом `-cor`
2. **Координаты зон** → JSON с постфиксом `-zones`
3. **OCR результаты** → JSON с постфиксом `-texts` 
4. **Исправленные данные** → JSON с постфиксом `-corrected`
5. **Итоговые данные** → JSON с постфиксом `-data`

**Структура итогового JSON (`-data.json`):**

Формируется FormExtractor на основе региональных OCR результатов:

```json
{
  "document_info": {
    "source_file": "034_compr-cor.jpg",
    "processing_date": "2025-11-13T12:00:00",
    "ocr_engine": "PaddleOCR",
    "language": "ru"
  },
  "header": {
    "act_number": {
      "value": "034/25",
      "confidence": 0.995,
      "source": "header",
      "validated": true,
      "suspicious": false
    },
    "act_date": {
      "value": "05.11.2025",
      "confidence": 0.998,
      "source": "header",
      "validated": true
    },
    "sticker_data": {
      "part_line_number": {
        "value": "11962",
        "confidence": 0.969,
        "source": "sticker"
      },
      "quantity_ordered": {
        "value": "85",
        "confidence": 0.930,
        "source": "sticker"
      }
    },
    "quantity_checked": {
      "value": "116",
      "confidence": 0.993,
      "source": "header",
      "validated": true
    },
    "control_type": {
      "value": "операционный",
      "confidence": 0.995,
      "source": "header"
    },
    "inspector_name": {
      "value": "Денисова Л.В",
      "confidence": 0.72,
      "source": "header",
      "suspicious": true
    }
  },
  "defects": [
    {
      "block_type": "geometry",
      "block_title": "ГЕОМЕТРИЯ И ОТВЕРСТИЯ",
      "column_headers": ["№", "ПАРАМЕТР", "ФАКТ/СТАТУС", "ОТКЛ", "КОЛ-ВО"],
      "rows": [
        {
          "row_number": "1",
          "parameter": "Смещение Ø4.2",
          "fact_value": "симметрия φ±0,3",
          "deviation": null,
          "quantity": "6",
          "confidence_avg": 0.78,
          "source_texts": ["Смещение Ø4.2", "симметрия φ±0,3", "6"]
        }
      ]
    },
    {
      "block_type": "surface",
      "block_title": "ПОВЕРХНОСТЬ",
      "column_headers": ["№", "ДЕФЕКТ", "КОЛ-ВО"],
      "rows": [
        {
          "row_number": "10",
          "defect": "Зарезна Ø2.2",
          "quantity": "3",
          "confidence_avg": 0.81
        }
      ]
    }
  ],
  "analysis": {
    "deviations": [
      {
        "row_number": "1-11",
        "operation": "ФРЗ 1,8",
        "cause": "Отрезка и матросенности новых стержневых дет.",
        "responsible": null,
        "decision": "Утилить.",
        "confidence_avg": 0.72
      }
    ],
    "final_decision": {
      "action": "не использовать",
      "quantity": 1,
      "manager_name": "Парынаев А.С.",
      "otk_representative": "Андрианова А.В."
    }
  },
  "validation_results": {
    "total_fields_validated": 7,
    "mandatory_fields_missing": [],
    "mandatory_fields_missing_count": 0,
    "suspicious_fields": ["inspector_name"],
    "errors": []
  },
  "corrections_applied": {
    "count": 5,
    "corrections": [...]
  },
  "processing_metrics": {
    "ocr_time_ms": 14242,
    "correction_time_ms": 2,
    "validation_time_ms": 1,
    "extraction_time_ms": 3200,
    "defect_blocks_detected": 2,
    "defect_rows_extracted": 12,
    "analysis_rows_extracted": 1,
    "total_time_ms": 17445
  }
}
```

**Модели данных (dataclasses):**

Используются простые dataclasses (KISS принцип, см. `src/models/form_data.py`):
- `FieldValue` - значение поля с метаданными (value, confidence, source, validated, suspicious)
- `StickerData` - данные наклейки (приоритетный источник)
- `HeaderData` - структура header секции (реквизиты документа, количества, контролёр)
- `DefectBlock` - блок таблицы дефектов (геометрия/отверстия/поверхность)
- `DefectRow` - строка таблицы дефектов
- `AnalysisData` - структура analysis секции
- `AnalysisRow` - строка таблицы отклонений
- `FinalDecision` - финальное решение и подписи
- `ValidationResult` - результаты валидации обязательных полей
- `ProcessingMetrics` - метрики обработки

## Мониторинг

**Принцип: простое логирование + базовые метрики**

**Что отслеживаем:**
- Время обработки каждого этапа пайплайна
- Качество OCR (confidence score)
- Количество успешно обработанных файлов
- Ошибки и исключения

**Инструменты:**
- **Python logging** - структурированные логи
- **Простые метрики** в JSON результатах
- **Файловые логи** с ротацией

**Метрики в результатах:**
```json
"processing_metrics": {
  "total_time_ms": 1500,
  "preprocessing_time_ms": 200,
  "ocr_time_ms": 800,
  "ocr_confidence": 0.92,
  "zones_detected": 3,
  "errors_count": 0
}
```

**Логирование:**
- INFO: начало/конец обработки файла
- WARNING: низкое качество OCR
- ERROR: ошибки обработки
- DEBUG: детальная информация для отладки

## Сценарии работы

**Основные сценарии использования:**

### 1. Обработка одного файла
```bash
python src/main.py --file images/report_2025-10-15_16-45-17.jpg
```
- Загрузка изображения
- Полный пайплайн обработки
- Сохранение результатов в `/results/`
- Вывод метрик в консоль

### 2. Пакетная обработка каталога
```bash
python src/main.py --batch images/ --mode pipeline
```
- Обработка всех изображений в каталоге
- Единая инициализация OCR движка (70-80% экономии времени)
- Сводный отчет по всем файлам в JSON
- Graceful degradation при ошибках отдельных файлов

### 3. Обработка с настройками
```bash
python src/main.py --file image.jpg --template otk_v2 --quality high
```
- Использование конкретного шаблона бланка
- Настройка качества обработки

**Выходные файлы для каждого изображения:**
- `filename-cor.jpg` - предобработанное изображение
- `filename-texts.json` - результаты OCR с региональным распознаванием (`regions_detected`, `ocr_results_by_region`)
- `filename-corrected.json` - исправленные данные OCR (сохраняет `ocr_results_by_region`)
- `filename-data.json` - итоговая структурированная структура данных (header, defects, analysis) с валидацией

**Типичный workflow:**
1. Поместить изображения в `/images/`
2. Запустить обработку
3. Получить результаты в `/results/`
4. Проанализировать логи при необходимости

## Деплой (локально)

**Принцип: максимально простая установка и запуск**

### Требования к системе
- Python 3.9+
- 2GB RAM (для PaddleOCR)
- 1GB свободного места на диске

### Установка и настройка
```bash
# 1. Клонирование/загрузка проекта
git clone <repository> или распаковка архива

# 2. Создание виртуального окружения
python -m venv venv
source venv/bin/activate  # Linux/Mac
# или
venv\Scripts\activate     # Windows

# 3. Установка зависимостей
pip install -r requirements.txt

# 4. Настройка конфигурации
cp .env.example .env
# Редактирование .env при необходимости

# 5. Проверка работоспособности
python src/main.py --help
```

### Структура после установки
```
Image_ocr/
├── venv/                # Виртуальное окружение
├── src/                 # Готовый к работе код
├── images/              # Папка для входных файлов
├── results/             # Папка для результатов
└── logs/                # Папка для логов (создается автоматически)
```

## Подход к конфигурированию

**Принцип: простые файлы конфигурации + переменные окружения**

### Структура конфигурации

**1. Основные настройки (.env файл):**
```bash
# Пути
INPUT_DIR=images
OUTPUT_DIR=results
LOG_DIR=logs

# OCR настройки
OCR_LANGUAGE=ru
OCR_CONFIDENCE_THRESHOLD=0.5
OCR_USE_GPU=false

# Обработка изображений
IMAGE_SCALE_FACTOR=2
ENABLE_PERSPECTIVE_CORRECTION=true  # Перспективная коррекция для мобильных фото
PERSPECTIVE_MIN_AREA_RATIO=0.2  # Минимальная площадь контура относительно изображения
PERSPECTIVE_CORNER_EPSILON=0.02  # Эпсилон для аппроксимации полигона
PERSPECTIVE_TARGET_WIDTH_LIMIT=3000  # Максимальная ширина после коррекции
PERSPECTIVE_TARGET_HEIGHT_LIMIT=2000  # Максимальная высота после коррекции
PERSPECTIVE_MIN_CORNER_DISTANCE=50  # Минимальное расстояние между углами (пиксели)
ENABLE_DESKEW=true
ENABLE_DENOISING=true

# Логирование
LOG_LEVEL=INFO
LOG_MAX_SIZE_MB=10
```

**2. Настройки детекции регионов:**
```bash
# Детекция зон бланка
ENABLE_REGION_DETECTION=true
REGION_DETECTION_STRATEGY=auto  # auto|template|adaptive|text_based
REGION_MIN_CONFIDENCE=0.7
REGION_MAX_WIDTH=3000
REGION_MAX_HEIGHT=2000
REGION_TEMPLATE_FILE=config/templates/regions.json
```
Параметры считываются через `Settings`. Если файл шаблонов не найден, RegionDetector использует встроенные определения (`otk_v1`, `otk_v2`). Ограничения ширины/высоты применяются к извлечённым зонам: пока каждая зона укладывается в допустимые пределы, разрешение всего изображения не уменьшается.

**3. Шаблоны бланков (JSON файлы):**
```python
# src/config/templates.py
TEMPLATES = {
    "otk_v1": "config/templates/otk_v1.json",
    "otk_v2": "config/templates/otk_v2.json"
}
```

**4. Pydantic для валидации:**
```python
# src/config/settings.py
from pydantic import BaseSettings

class Settings(BaseSettings):
    input_dir: str = "images"
    output_dir: str = "results"
    ocr_confidence_threshold: float = 0.5
    log_level: str = "INFO"
    
    class Config:
        env_file = ".env"
```

**Приоритет настроек:**
1. Переменные окружения
2. .env файл  
3. Значения по умолчанию

## Подход к логгированию

**Принцип: отдельный лог-файл для каждого запуска**

### Структура логирования

**Файловая структура:**
```
logs/
├── app_2025-11-08_10-30-15.log    # Запуск в 10:30:15
├── app_2025-11-08_14-22-03.log    # Запуск в 14:22:03
└── app_2025-11-08_16-45-12.log    # Запуск в 16:45:12
```

**Формат имени файла:**
```
app_YYYY-MM-DD_HH-MM-SS.log
```

**Уровни логирования:**
- **INFO** - основные события обработки
- **WARNING** - предупреждения
- **ERROR** - ошибки обработки

**Формат сообщений:**
```
2025-11-08 10:30:15 - INFO - Processing image: report_001.jpg
2025-11-08 10:30:16 - WARNING - Low OCR confidence: 0.65
2025-11-08 10:30:17 - INFO - Processing completed in 1.5s
```

**Настройки:**
- Логи в консоль + файл
- Автоматическое создание имени файла при запуске
- Сохранение логов за последние 30 дней (настраивается)

## Подход к проектной документации

**Принцип: минимум необходимой документации**

### Структура документации
```
docs/
├── vision.md            # Техническое видение (этот документ)
├── README.md            # Быстрый старт и основная информация
└── api.md               # Описание модулей и функций (при необходимости)
```

**Содержание документов:**
- **README.md** - установка, запуск, примеры использования
- **vision.md** - техническое видение и архитектура
- **Комментарии в коде** - docstrings для основных функций

**Принципы:**
- Документация пишется по мере необходимости
- Приоритет - понятный код над подробной документацией
- Обновление документации при значимых изменениях

## Оптимизация производительности пакетной обработки

**Проблема:** Инициализация PaddleOCR для каждого файла занимает 70-80% времени обработки.

**Решение:** Shared OCR Engine Pattern
- Единая инициализация PaddleOCR для всего батча
- Переиспользование модели между файлами
- Context manager для управления жизненным циклом

**Архитектурные принципы:**
- Single-threaded обработка (KISS principle)
- Явное управление ресурсами через context managers
- Graceful degradation при ошибках отдельных файлов

**Результаты оптимизации:**
```python
# Без оптимизации (каждый файл инициализирует OCR):
# 6 файлов × (3.2s инициализация + 7.0s обработка) = ~61 секунда

# С оптимизацией (shared engine):
# 3.2s инициализация + 6 × 7.0s обработка = ~45 секунд
# Экономия: ~25% для 6 файлов, до 70-80% для больших батчей
```

**Использование:**
```bash
# Пакетная обработка директории
python src/main.py --batch images/ --mode pipeline

# Только OCR для директории
python src/main.py --batch images/ --mode ocr
```

## Адаптивное масштабирование разрешения

**Проблема:** Низкое разрешение снижает точность OCR, но избыточное масштабирование замедляет обработку.

**Решение:** Адаптивное масштабирование на основе мегапикселей:

### Алгоритм масштабирования

1. **Определение исходного разрешения:**
   - Расчет мегапикселей: MP = (width × height) / 1,000,000

2. **Логика масштабирования:**
   - Если MP ≥ 5.0 → пропустить масштабирование (достаточное качество)
   - Если MP < 5.0 → масштабировать до ~8 MP (целевое разрешение)

3. **Ограничения:**
   - Максимальные размеры: 3500×2500 пикселей
   - Сохранение соотношения сторон (ортогональное масштабирование)
   - Интерполяция: INTER_CUBIC для увеличения

**Примеры:**
- 1920×1080 (2.1 MP) → масштабируется до ~3758×2114 (~7.9 MP)
- 2560×1440 (3.7 MP) → масштабируется до ~3342×1879 (~6.3 MP)
- 3264×2448 (8.0 MP) → без изменений (≥5 MP)
- 4000×3000 (12 MP) → без изменений (≥5 MP)

**Преимущества:**
- Оптимальное качество OCR без избыточной обработки
- Экономия времени на высоких разрешениях
- Улучшение точности на низких разрешениях

**Конфигурация:**
```python
# src/config/settings.py
enable_adaptive_scaling: bool = True
adaptive_scaling_min_mp: float = 5.0
adaptive_scaling_target_mp: float = 6.0  # Снижено с 8.0 для стабильности OCR
adaptive_scaling_max_width: int = 3000   # Снижено с 3500 (рекомендация PaddleOCR)
adaptive_scaling_max_height: int = 2000  # Снижено с 2500
```

### Ограничения размера для OCR

**Проблема:** PaddleOCR имеет ограничения по максимальному размеру изображений (Out of Memory, segfault на больших изображениях).

**Решение:** Многоуровневая защита от превышения размера:

1. **Адаптивное масштабирование (preprocessing):**
   - Ограничение целевого разрешения: 6 MP (было 8 MP)
   - Максимальные размеры: 3000×2000 px (было 3500×2500 px)

2. **Защитное downscaling (OCR engine):**
   - Проверка размера перед OCR
   - Если max(width, height) > 3000px → автоматическое уменьшение
   - Сохранение соотношения сторон
   - Использование INTER_AREA для качественного downscaling

3. **Ограничения PaddleOCR:**
   - `det_limit_side_len: 2000` - ограничение детекции текста
   - `det_limit_type: max` - применение к максимальной стороне

**Рекомендации PaddleOCR:**
- Максимальный безопасный размер: 3000px по длинной стороне
- Для очень больших изображений: batch processing по частям
- Мониторинг памяти при обработке

**Логирование:**
- WARNING при downscaling изображения
- DEBUG информация о размерах на каждом этапе
- ERROR с полным stack trace при сбоях OCR

**Конфигурация:**
```python
# src/config/settings.py
ocr_max_image_dimension: int = 3000  # Max dimension for OCR
ocr_det_limit_side_len: int = 2000   # PaddleOCR detection limit
```

### Детальное диагностическое логирование

**Проблема:** При сбоях OCR недостаточно информации для диагностики - где и почему теряются данные.

**Решение:** Многоуровневое детальное логирование на уровне DEBUG:

1. **Анализ структуры результатов OCR:**
   - Тип и размер данных на каждом уровне
   - Типы элементов в списках и объектах
   - Preview содержимого для быстрой диагностики

2. **Валидация на каждом этапе:**
   - Проверка None/empty перед обработкой
   - Детальная диагностика первой страницы результатов
   - Определение формата данных (PaddleX vs standard)

3. **Детальная обработка каждого текста:**
   - Логирование типов bbox и text_info
   - Отслеживание причин пропуска (низкая уверенность/ошибки)
   - Счетчики: обработано/пропущено/ошибок

4. **Параметры изображений:**
   - Размеры и megapixels
   - Цветовое пространство и каналы
   - Тип данных и диапазон значений

5. **Итоговая статистика:**
   - Количество обработанных элементов
   - Количество пропущенных (по причинам)
   - Финальное количество детекций

**Включение детального логирования:**
```bash
# В .env или переменной окружения
LOG_LEVEL=DEBUG
LOG_OCR_VERBOSE=true  # Дополнительное OCR логирование (будущее)
SAVE_OCR_DEBUG_FILES=true  # Сохранение промежуточных файлов (будущее)
```

**Пример вывода DEBUG лога:**
```
============================================================
OCR RESULTS STRUCTURE ANALYSIS
============================================================
ocr_results type: list
ocr_results length: 1
  Page 0 type: list
  Page 0 length: 15 items
    First item type: list
    First item preview: [[[x1,y1],[x2,y2]...], ['текст', 0.95]]
============================================================
PROCESSING OCR RESULTS
============================================================
First page list length: 15
Processing standard PaddleOCR format
Items to process: 15
  Processing line 1/15
    text: 'ГЕОМЕТРИЯ', confidence: 0.950
    ✓ ADDED to detections (total: 1)
Standard format processing summary:
  Total items: 15
  Successfully processed: 12
  Skipped (low confidence): 2
  Skipped (errors): 1
  Final detections: 12
```

**Преимущества:**
- Точная диагностика проблем парсинга OCR результатов
- Понимание формата данных от PaddleOCR
- Отслеживание потери данных на каждом этапе
- Быстрое выявление проблем с уверенностью распознавания

## План разработки по итерациям

**Итерация 1: Базовая инфраструктура** ✅
- Настройка проекта и зависимостей
- Базовая структура модулей
- Конфигурация и логирование
- Простой main.py для тестирования

**Итерация 2: Предобработка изображений** ✅
- Модуль коррекции искажений и наклона
- Перспективная коррекция для мобильных фото (улучшение OCR на 30-50%)
- Коррекция наклона текста (deskew)
- Улучшение качества изображения
- Сохранение результатов с постфиксом `-cor`

**Итерация 3: OCR распознавание** ✅
- Интеграция PaddleOCR
- Распознавание текста полного изображения
- Сохранение результатов с постфиксом `-texts`
- Обработка confidence score

**Итерация 4: Улучшение OCR и коррекция ошибок**
- Словарь исправления частых ошибок OCR
- Постобработка результатов распознавания
- Валидация числовых полей и дат
- Тестирование улучшений на существующих результатах

**Итерация 5: Детекция зон и структурирование данных**
- Гибридная детекция зон (шаблоны + адаптивное распознавание)
- Извлечение данных по секциям формы
- Определение назначения колонок
- Создание структурированного JSON

**Итерация 6: Система шаблонов и валидация**
- Конфигурируемые шаблоны бланков
- Правила валидации полей
- Сопоставление с шаблонами
- Итоговая структура данных с метаданными

**Итерация 7: Пакетная обработка и финализация** ✅
- Оптимизация OCR движка (shared instance pattern)
- Context manager для управления жизненным циклом
- Модуль пакетной обработки каталога
- Сводные отчеты с метриками
- Интеграция в CLI main.py

---

*Документ создан: 2025-11-08*  
*Последнее обновление: 2025-11-13*
*Версия: 1.0*

